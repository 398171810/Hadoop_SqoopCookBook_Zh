目前为止，我们通过使用一些事例说明如何将一张表中的所有内容从数据库中传输到hadoop中。如果需要将hadoop中的数据和关系数据库中的数据同步时应如何操作。
可以每天获取一份最新的数据拷贝然后覆盖所有的数据，但这不是最理想的方法。导入数据所需的时间将随着每日追加到表中的附加数据量的比例增加这将导致非必要
的数据库负载消耗，为何要重复导入已经导入的数据呢,对于传输数据的增量。本章使用的事例表是visits，并且在上一章中已经创建了这张表。

<h2>3.1只导入新数据</h2>

<h3>问题<h3>
有一张数据库表的主键类型是integer，只需要导入新数据，需要周期性的进行数据同步，以便将来处理。

<h3>解决方案</h3>

通过参数**--incremental**来激活sqoop的增量特征，该参数的值将是增量导入的类型。当表只会增加新列，并且原来的数据不会改变，使用追加模式。
增量导入也需要两个额外的参数**--check-column**指示进行追加数据是依据列的列名。对于参数**--last-value**包含最后一次被成功导入的数据。

以下事例将会只传输id值大于1的行:

```
sqoop import \
--connect jdbc:mysql://mysql.example.com/sqoop \
--username sqoop \
--password sqoop \
--table visits \
--incremental append \
--check-column id \
--last-value 1
```

<h3>讨论</h3>
增量导入以追加模式允许只导入新加的行，与每次需要同步数据时进行完全导入相比, 这节省了大量资源。一个缺点是需要知道最后一个导入行的值, 以便下一次 
Sqoop 可以从结束位置开始,sqoop在允许一次增量模式时总是会打印出上次导入的最后的值。这可以让你轻松地捡起你离开的地方。下面是在追加模式下执行增量导入
时打印出来的示例输出

```
13/03/18 08:16:36 INFO tool.ImportTool: Incremental import complete! ...
13/03/18 08:16:36 INFO tool.ImportTool: --incremental append
13/03/18 08:16:36 INFO tool.ImportTool: --check-column id
13/03/18 08:16:36 INFO tool.ImportTool: --last-value 2
Any changed rows that were already imported from previ
```


























