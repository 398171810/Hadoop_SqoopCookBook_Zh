<h2>2.6压缩导入的数据</h2>

<h3>问题</h3>
当你想要通过使用压缩生成的文件,已达到减少文件在HDFS上的占用空间。

<h3>解决方案</h3>

使用这个参数 **--compress** 来达到压缩的目的:

```
sqoop import \
    --connect jdbc:mysql://mysql.example.com/sqoop \
    --username sqoop \
    --table citeis \
    --compress
```

<h3>讨论</h3>

sqoop 利用了Hadoop的内在的并行执行优势，这种优势是借助了Hadoop的处理引擎MapReduce进行数据的传输，由于MapReduce能够出色的支持压缩
,sqoop只是简单的复用这种强大的功能来提供压缩功能。默认情况下使用**--compress**参数，输出的文件将会被用gzip方式压缩，并且所有的文件
以.gz后缀结尾。可以选择其他的编码方式，通过参数 **--compression-codec** 参数，以下事例使用BZip2压缩方式替换GZip：

```
sqoop import --compress \
    --compression-codec org.apache.hadoop.io.compress.BZip2Codec
```

利用 MapReduce 压缩能力的另一个好处是 Sqoop使用所有的Hadoop压缩编码是开箱即用的，无须通过sqoop来进行
授权压缩编码。也就是说，sqoop无法使用Hadoop无法理解的压缩算法。在使用压缩编码前，确保期望的编码
被正确的安装和配置在你集群上的所有节点。

由于sqoop是委托MapReduce引擎进行压缩，你需要确保在 Hadoop 中允许压缩地图输出配置,举例来说：如果在文件mapred-site.xml中
**prop‐erty mapred.output.compress** 属性的值被设置位false，这样Sqoop将无法使用压缩输出文件功能，即使用了 **--compress** 参数.

选择使用的压缩方式可能会明显的影响随后的处理。某些编解码器不支持查找压缩文件的中间部分而不读取所有内容, 这样将显著地影响Hadoop
以并行方式处理输入文件。您应该使用 splittable 编解码器数据, 这些数据计划在后续处理中使用。以下表格对splittable和非splittable方式的对比说明：

|       splittable        |          not splittabel             |
|:-------------------------|-------------------------------------|
|  BZip,LZO               |           GZip,Snappy               |                     


